{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPuTJwSjNftZ9kHlZIv7kwx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["```\n","Generative AI with Python, by Fernando Amaral\n","```"],"metadata":{"id":"vMs6nnSGuGMr"}},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"NrQJQOCqst9J"}},{"cell_type":"code","source":["#gpu\n","!pip install diffusers transformers accelerate safetensors"],"metadata":{"id":"DbHXLI3IbHtG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from diffusers import DiffusionPipeline\n","from diffusers.utils import export_to_video"],"metadata":{"id":"-63IqiUXLSvw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Code"],"metadata":{"id":"Jb_UXVAUszL9"}},{"cell_type":"code","source":["def load_pretrained_diffusion_pipeline(model_path: str, device: str = \"cuda\", dtype: torch.dtype = torch.float16, variant: str = \"fp16\") -> DiffusionPipeline:\n","    pipeline = DiffusionPipeline.from_pretrained(model_path, torch_dtype=dtype, variant=variant).to(device)\n","    return pipeline"],"metadata":{"id":"M7Iq28zFp7CG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_video_from_prompt(pipeline: DiffusionPipeline, prompt: str, inference_steps: int, frames: int) -> torch.Tensor:\n","    video_data = pipeline(prompt=prompt, num_inference_steps=inference_steps, num_frames=frames)\n","    return video_data.frames"],"metadata":{"id":"-2rjggeWp8lO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main():\n","    DEVICE = \"cuda\"\n","    TORCH_DTYPE = torch.float16\n","    VARIANT = \"fp16\"\n","    MODEL_PATH = \"damo-vilab/text-to-video-ms-1.7b\"\n","    PROMPT = \"Superman dancing in the rain\"\n","    INFERENCE_STEPS = 50\n","    FRAMES = 32  # default: 16\n","    OUTPUT_FILENAME = \"superman.mp4\"\n","\n","    pipeline = load_pretrained_diffusion_pipeline(MODEL_PATH, DEVICE, TORCH_DTYPE, VARIANT)\n","\n","    video_frames = generate_video_from_prompt(pipeline, PROMPT, INFERENCE_STEPS, FRAMES)\n","\n","    export_to_video(video_frames, OUTPUT_FILENAME)"],"metadata":{"id":"OKmedtZUp8v_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Execution"],"metadata":{"id":"Qv8UiJwVs2Gu"}},{"cell_type":"code","source":["main()"],"metadata":{"id":"TZtYue_vyBOd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Fgs46yNysqgz"},"execution_count":null,"outputs":[]}]}